"""
RAG ì²´ì¸ - LLMê³¼ ì§€ì‹ë² ì´ìŠ¤ ì—°ë™ (XAI ì‹¬ì¸µ ë¶„ì„ + í’ì„±í•œ ì‹ë‹¨ ë²„ì „)
"""
import time
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from typing import List, Dict, Optional, Union

from .knowledge_base import KnowledgeBase
from ..config import GOOGLE_API_KEY, LLM_MODEL, LLM_TEMPERATURE, LLM_MAX_TOKENS

class FitLifeRAG:
    """FitLife AI RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.kb = KnowledgeBase()
        
        # ì‚¬ìš©ìê°€ ì„±ê³µí•œ Gemini 2.5 ëª¨ë¸ ìœ ì§€
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash", 
            google_api_key=GOOGLE_API_KEY,
            temperature=0.3, # ì„¤ëª…ì„ ìœ„í•´ ì°½ì˜ì„± ì•½ê°„ ë†’ì„
            max_output_tokens=4096 # ë‹µë³€ ê¸¸ê²Œ í•˜ë„ë¡ í† í° ëŠ˜ë¦¼
        )

    def query(
        self, 
        user_query: str, 
        user_profile: Optional[Union[Dict, object]] = None,
        search_categories: Optional[List[str]] = None,
        mode: str = "general" # ëª¨ë“œ ë¶€í™œ
    ) -> Dict:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„± (XAI ê°•í™”)
        """
        
        # 1. [ê²€ìƒ‰ì–´ í™•ì¥] AIê°€ ë” ë˜‘ë˜‘í•˜ê²Œ ì°¾ë„ë¡ í‚¤ì›Œë“œ ì¶”ê°€
        enhanced_query = user_query
        target_goal = ""
        if isinstance(user_profile, dict): target_goal = user_profile.get("goal", "")
        elif hasattr(user_profile, "goal"): target_goal = user_profile.goal
            
        if mode == "food":
            enhanced_query += f" {target_goal} ê³ ë‹¨ë°± ì €ì§€ë°© ì‹ì´ì„¬ìœ  ì˜ì–‘ì„±ë¶„ íš¨ëŠ¥"
        elif mode == "exercise":
            enhanced_query += f" {target_goal} ìš´ë™íš¨ê³¼ ìê·¹ë¶€ìœ„ ì£¼ì˜ì‚¬í•­"

        # 2. [ë°ì´í„° í™•ë³´] 5ê°œëŠ” ë„ˆë¬´ ì ìŒ -> 15ê°œë¡œ ëŠ˜ë¦¼
        search_results_raw = []
        if search_categories:
            for category in search_categories:
                # 15ê°œ ì •ë„ë©´ ì‹ë‹¨ ì§œê¸°ì— ì¶©ë¶„í•˜ê³  ì†ë„ë„ ê´œì°®ìŒ
                results = self.kb.search(enhanced_query, top_k=30, category=category)
                search_results_raw.extend(results)
        else:
            search_results_raw = self.kb.search(enhanced_query, top_k=15)
        
        # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self._build_context(search_results_raw)
        profile_info = self._format_profile(user_profile) if user_profile else ""
        
        # 4. [XAI í”„ë¡¬í”„íŠ¸] ìƒì„¸ ì„¤ëª…ì„ ê°•ì œí•˜ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt, user_message = self._create_xai_prompt(mode, profile_info, user_query, context)
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_message)
        ]
        
        # 5. LLM í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨ - 429 ì—ëŸ¬ ë°©ì§€)
        response_content = ""
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                response = self.llm.invoke(messages)
                response_content = response.content
                break 
            except Exception as e:
                error_msg = str(e)
                if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
                    if attempt < max_retries - 1:
                        time.sleep(10) # 10ì´ˆ ëŒ€ê¸°
                        continue
                    else:
                        response_content = "âš ï¸ ì‚¬ìš©ëŸ‰ì´ ë§ì•„ ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”."
                else:
                    response_content = f"ì˜¤ë¥˜ ë°œìƒ: {e}"
                    break
        
        # 6. ê²°ê³¼ ë°˜í™˜
        formatted_sources = []
        for doc, score in search_results_raw:
            source_item = doc.metadata.copy()
            source_item['content'] = doc.page_content
            source_item['score'] = score
            formatted_sources.append(source_item)

        return {
            "answer": response_content,
            "sources": formatted_sources,
            "confidence": self._calculate_confidence(search_results_raw)
        }
    
    def _create_xai_prompt(self, mode, profile_info, query, context):
        """
        â˜… [í•µì‹¬] AIì—ê²Œ 'ì„¤ëª… ê°€ëŠ¥í•œ AI(XAI)' ì—­í• ì„ ë¶€ì—¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸
        """
        
        base_instruction = """
        [ì§€ì¹¨]
        1. ë°˜ë“œì‹œ [ì°¸ê³  ìë£Œ]ì— ìˆëŠ” ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
        2. ì¶”ì²œí•˜ëŠ” ì´ìœ ë¥¼ 'ì˜ì–‘í•™ì  ê´€ì 'ê³¼ 'ì‚¬ìš©ì ê±´ê°• ìƒíƒœ'ì— ë§ì¶° ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.
        3. ê° ìŒì‹/ìš´ë™ë§ˆë‹¤ ê¸°ëŒ€ íš¨ê³¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
        4. ê°™ì€ ìŒì‹/ìš´ë™ì„ ì¤‘ë³µí•´ì„œ ì¶”ì²œí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
        """

        if mode == "food":
            system_prompt = f"""ë‹¹ì‹ ì€ 'ì„ìƒ ì˜ì–‘ ì „ë¬¸ AI'ì…ë‹ˆë‹¤. 
            ë‹¨ìˆœíˆ ë©”ë‰´ë§Œ ë‚˜ì—´í•˜ì§€ ë§ê³ , **ì™œ ì´ ìŒì‹ì´ ì‚¬ìš©ìì˜ ëª©í‘œ(ë‹¤ì´ì–´íŠ¸/ê·¼ìœ¡ ë“±)ì™€ ì§ˆí™˜(ë‹¹ë‡¨ ë“±)ì— ì¢‹ì€ì§€** ì˜í•™/ì˜ì–‘í•™ì  ê·¼ê±°ë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ì„¸ìš”.
            
            [ì¶œë ¥ í˜•ì‹]
            1. ğŸ“Š **ì‚¬ìš©ì ê±´ê°• ë¶„ì„**: í˜„ì¬ ìƒíƒœì™€ ì‹ë‹¨ ì „ëµ ìš”ì•½
            2. ğŸ½ï¸ **ë§ì¶¤ ì‹ë‹¨ ì œì•ˆ**: ì•„ì¹¨/ì ì‹¬/ì €ë…/ê°„ì‹ (ì¹¼ë¡œë¦¬ í¬í•¨)
            3. ğŸ’¡ **ì˜ì–‘ ë¶„ì„ (XAI)**: 
               - ì„ ì • ì´ìœ : (ì˜ˆ: ë‹¹ë‡¨ê°€ ìˆìœ¼ë¯€ë¡œ GI ì§€ìˆ˜ê°€ ë‚®ì€ í˜„ë¯¸ë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤)
               - ê¸°ëŒ€ íš¨ê³¼: (ì˜ˆ: ë‹¨ë°±ì§ˆ 20gì€ ê·¼ìœ¡ íšŒë³µì„ ë•ìŠµë‹ˆë‹¤)
            
            {base_instruction}
            """
        elif mode == "exercise":
            system_prompt = f"""ë‹¹ì‹ ì€ 'ì „ë¬¸ ìŠ¤í¬ì¸  ì˜í•™ AI'ì…ë‹ˆë‹¤.
            ë‹¨ìˆœíˆ ìš´ë™ë§Œ ë‚˜ì—´í•˜ì§€ ë§ê³ , **ì™œ ì´ ìš´ë™ì´ ì‚¬ìš©ìì—ê²Œ í•„ìš”í•œì§€** ìƒë¦¬í•™ì  ê·¼ê±°ë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ì„¸ìš”.
            
            [ì¶œë ¥ í˜•ì‹]
            1. ğŸ“Š **ìš´ë™ ëŠ¥ë ¥ ë¶„ì„**: ì‚¬ìš©ì ìƒíƒœ ìš”ì•½
            2. ğŸ’ª **ì˜¤ëŠ˜ì˜ ë£¨í‹´**: ìš´ë™ ì¢…ëª©, ì„¸íŠ¸, íšŸìˆ˜
            3. ğŸ’¡ **ìš´ë™ íš¨ê³¼ ë¶„ì„ (XAI)**:
               - ì„ ì • ì´ìœ : (ì˜ˆ: ê´€ì ˆì´ ì•½í•˜ë¯€ë¡œ ì €ì¶©ê²© ìš´ë™ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤)
               - íƒ€ê²Ÿ ë¶€ìœ„: (ì˜ˆ: ëŒ€í‰ê·¼ê³¼ ì‚¼ë‘ê·¼ì„ ìê·¹í•©ë‹ˆë‹¤)
            
            {base_instruction}
            """
        else:
            system_prompt = f"ë‹¹ì‹ ì€ FitLife AIì…ë‹ˆë‹¤. ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”. {base_instruction}"

        user_message = f"{profile_info}\n[ì§ˆë¬¸]: {query}\n[ì°¸ê³  ìë£Œ]:\n{context}"
        return system_prompt, user_message

    def _build_context(self, search_results: List) -> str:
        if not search_results: return "ê´€ë ¨ ìë£Œ ì—†ìŒ."
        context_parts = []
        for i, (doc, score) in enumerate(search_results, 1):
            source = doc.metadata.get("source", "ì¶œì²˜ ë¯¸ìƒ")
            title = doc.metadata.get("title", "ì œëª© ì—†ìŒ")
            content = doc.page_content
            context_parts.append(f"[{i}] {title} | {content} (ì¶œì²˜: {source})")
        return "\n".join(context_parts)
    
    def _format_profile(self, profile: Union[Dict, object]) -> str:
        parts = ["[ì‚¬ìš©ì ì •ë³´]"]
        if isinstance(profile, dict):
            if "age" in profile: parts.append(f"ë‚˜ì´: {profile['age']}")
            if "goal" in profile: parts.append(f"ëª©í‘œ: {profile['goal']}")
            if "diseases" in profile: parts.append(f"ì§ˆí™˜: {profile['diseases']}")
            if "allergies" in profile: parts.append(f"ì•ŒëŸ¬ì§€: {profile['allergies']}")
        else:
            if hasattr(profile, 'age'): parts.append(f"ë‚˜ì´: {profile.age}")
            if hasattr(profile, 'goal'): parts.append(f"ëª©í‘œ: {profile.goal}")
        return "\n".join(parts)
    
    def _calculate_confidence(self, search_results: List) -> float:
        if not search_results: return 0.0
        scores = [score for doc, score in search_results[:3]]
        return sum(scores) / len(scores) if scores else 0.0