"""
RAG ëª¨ë“ˆ - ì§€ì‹ë² ì´ìŠ¤ êµ¬ì¶• ë° ê²€ìƒ‰
"""
import chromadb
from chromadb.config import Settings
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from typing import List, Dict, Optional
import json
from pathlib import Path

from .config import (
    GOOGLE_API_KEY, 
    CHROMA_PERSIST_DIR, 
    COLLECTION_NAME,
    EMBEDDING_MODEL,
    RAG_TOP_K
)


class KnowledgeBase:
    """ê±´ê°• ì§€ì‹ë² ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model=EMBEDDING_MODEL,
            google_api_key=GOOGLE_API_KEY
        )
        
        # ChromaDB ì´ˆê¸°í™”
        self.client = chromadb.PersistentClient(path=CHROMA_PERSIST_DIR)
        
        # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        self.collection = self.client.get_or_create_collection(
            name=COLLECTION_NAME,
            metadata={"description": "FitLife AI ê±´ê°• ì§€ì‹ë² ì´ìŠ¤"}
        )
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ".", " "]
        )
    
    def add_documents(self, documents: List[Dict], category: str):
        """
        ë¬¸ì„œ ì¶”ê°€
        
        Args:
            documents: [{"title": "...", "content": "...", "source": "..."}, ...]
            category: "food" | "exercise" | "guideline"
        """
        for i, doc in enumerate(documents):
            # í…ìŠ¤íŠ¸ ë¶„í• 
            chunks = self.text_splitter.split_text(doc["content"])
            
            for j, chunk in enumerate(chunks):
                # ì„ë² ë”© ìƒì„±
                embedding = self.embeddings.embed_query(chunk)
                
                # ChromaDBì— ì¶”ê°€
                doc_id = f"{category}_{i}_{j}"
                self.collection.add(
                    ids=[doc_id],
                    embeddings=[embedding],
                    documents=[chunk],
                    metadatas=[{
                        "title": doc.get("title", ""),
                        "category": category,
                        "source": doc.get("source", ""),
                        "chunk_index": j
                    }]
                )
        
        print(f"âœ… {len(documents)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ (ì¹´í…Œê³ ë¦¬: {category})")
    
    def search(self, query: str, top_k: int = RAG_TOP_K, category: Optional[str] = None) -> List[Dict]:
        """
        ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            category: ì¹´í…Œê³ ë¦¬ í•„í„° (ì„ íƒ)
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embeddings.embed_query(query)
        
        # ê²€ìƒ‰ ì¡°ê±´
        where_filter = {"category": category} if category else None
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=where_filter,
            include=["documents", "metadatas", "distances"]
        )
        
        # ê²°ê³¼ ì •ë¦¬
        search_results = []
        for i in range(len(results["ids"][0])):
            search_results.append({
                "id": results["ids"][0][i],
                "content": results["documents"][0][i],
                "metadata": results["metadatas"][0][i],
                "score": 1 - results["distances"][0][i]  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
            })
        
        return search_results
    
    def get_stats(self) -> Dict:
        """ì§€ì‹ë² ì´ìŠ¤ í†µê³„"""
        return {
            "total_documents": self.collection.count(),
            "collection_name": COLLECTION_NAME
        }
    
    def clear(self):
        """ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        self.client.delete_collection(COLLECTION_NAME)
        self.collection = self.client.get_or_create_collection(
            name=COLLECTION_NAME,
            metadata={"description": "FitLife AI ê±´ê°• ì§€ì‹ë² ì´ìŠ¤"}
        )
        print("ğŸ—‘ï¸ ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")


def load_knowledge_from_json(filepath: str) -> List[Dict]:
    """JSON íŒŒì¼ì—ì„œ ì§€ì‹ ë¡œë“œ"""
    with open(filepath, "r", encoding="utf-8") as f:
        return json.load(f)


# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    kb = KnowledgeBase()
    print(f"ğŸ“Š ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœ: {kb.get_stats()}")
